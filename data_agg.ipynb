{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "configParser = configparser.RawConfigParser()\n",
    "configFilePath = r\"config.txt\"\n",
    "configParser.read(configFilePath)\n",
    "cacheDfPath = r\"cache/gw19trainingdf.pkl\"\n",
    "display_cols = [\n",
    "    \"name\",\n",
    "    \"position\",\n",
    "    \"team\",\n",
    "    \"gw\",\n",
    "    \"xP\",\n",
    "    \"total_points\",\n",
    "    \"tot_total_points\",\n",
    "    \"recent_total_points\",\n",
    "    \"avg_total_points\",\n",
    "]\n",
    "\n",
    "id_to_team_name_df = pd.read_csv(\"data/teams.csv\")\n",
    "id_to_team_name_map = id_to_team_name_df.set_index(\"id\")[\"name\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_dataframe(gw_dir_path=\"data/gws\"):\n",
    "    gw_dfs = []\n",
    "    gw_file_list = glob.glob(f\"{gw_dir_path}/gw*.csv\")\n",
    "    for gw_file in gw_file_list:\n",
    "        curr_gw_csv = pd.read_csv(gw_file)\n",
    "        # Keep this list of columns\n",
    "        column_names = configParser.get(\"Data\", \"pred_column_names\").split(\n",
    "            \",\"\n",
    "        ) + configParser.get(\"Data\", \"res_column_names\").split(\",\")\n",
    "        curr_gw_csv = curr_gw_csv[column_names]\n",
    "        curr_gw_csv[\"gw\"] = int(\n",
    "            (gw_file.removeprefix(f\"{gw_dir_path}\\\\gw\")).removesuffix(\".csv\")\n",
    "        )\n",
    "        gw_dfs.append(curr_gw_csv)\n",
    "\n",
    "    agg_df = pd.concat(gw_dfs, ignore_index=True)\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "init_df = create_initial_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/429 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [00:04<00:00, 93.54it/s] \n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def preprocess_df(df):\n",
    "    # First we ignore all non-starts\n",
    "    df = df[df[\"starts\"] == 1].copy()\n",
    "\n",
    "    # Iterate through each player now\n",
    "    player_dfs = []\n",
    "    min_starts = int(configParser.get(\"Preprocessing\", \"min_starts\"))\n",
    "    stat_list = configParser.get(\"Preprocessing\", \"stat_list\").split(\",\")\n",
    "    recent_num_gws = int(configParser.get(\"Preprocessing\", \"recent_num_gws\"))\n",
    "\n",
    "    for name, player_df in tqdm(df.groupby(by=\"name\")):\n",
    "        # Filter only players with >= min_starts\n",
    "        if len(player_df) < min_starts:\n",
    "            continue\n",
    "\n",
    "        player_df = player_df.sort_values(\"gw\")\n",
    "\n",
    "        for stat in stat_list:\n",
    "            # Shift to ignore current row\n",
    "            player_df[f\"tot_{stat}\"] = player_df[f\"{stat}\"].shift(fill_value=0).cumsum()\n",
    "            player_df[f\"avg_{stat}\"] = (\n",
    "                player_df[f\"tot_{stat}\"] / player_df[f\"tot_starts\"]\n",
    "            )\n",
    "            player_df[f\"avg_{stat}\"].fillna(0, inplace=True)\n",
    "\n",
    "            # closed = 'left' to ignore current row\n",
    "            player_df[f\"recent_{stat}\"] = (\n",
    "                player_df[f\"{stat}\"].rolling(recent_num_gws, closed=\"left\").mean()\n",
    "            )\n",
    "\n",
    "        player_dfs.append(player_df)\n",
    "\n",
    "    return pd.concat(player_dfs)\n",
    "\n",
    "\n",
    "def compute_team_agg(df, team, gw):\n",
    "    df = df[df[\"team\"] == team]\n",
    "    df = df[df[\"gw\"] == gw]\n",
    "    df = df[df[\"starts\"] == 1]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if os.path.exists(cacheDfPath):\n",
    "    preprocessed_df = pd.read_pickle(cacheDfPath)\n",
    "else:\n",
    "    preprocessed_df = preprocess_df(init_df)\n",
    "\n",
    "    def compute_opp_team_stats(df, df_row, position, stat):\n",
    "        opp_df = compute_team_agg(\n",
    "            df, id_to_team_name_map[df_row[\"opponent_team\"]], df_row[\"gw\"]\n",
    "        )\n",
    "        return np.mean(opp_df[opp_df[\"position\"] == position][stat])\n",
    "\n",
    "    def compute_team_stats(df, df_row, position, stat):\n",
    "        team_df = compute_team_agg(df, df_row[\"team\"], df_row[\"gw\"])\n",
    "        return np.mean(team_df[team_df[\"position\"] == position][stat])\n",
    "\n",
    "    for position in tqdm([\"GK\", \"DEF\", \"MID\", \"FWD\"]):\n",
    "        for stat in configParser.get(\"Preprocessing\", \"stat_list\").split(\",\"):\n",
    "            preprocessed_df[f\"opp_{position}_recent_{stat}\"] = preprocessed_df.apply(\n",
    "                lambda df_row: compute_opp_team_stats(\n",
    "                    preprocessed_df, df_row, position, f\"recent_{stat}\"\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "            preprocessed_df[f\"team_{position}_recent_{stat}\"] = preprocessed_df.apply(\n",
    "                lambda df_row: compute_opp_team_stats(\n",
    "                    preprocessed_df, df_row, position, f\"recent_{stat}\"\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "\n",
    "    preprocessed_df.to_pickle(cacheDfPath)\n",
    "\n",
    "display(preprocessed_df[display_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Linear Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(df, cols):\n",
    "    for col in cols:\n",
    "        if df[col].std() > 0.0001:\n",
    "            df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "\n",
    "all_preds = (\n",
    "    [\"was_home\"]\n",
    "    + flatten(\n",
    "        [\n",
    "            [f\"recent_{stat}\", f\"avg_{stat}\", f\"total_{stat}\"]\n",
    "            for stat in configParser.get(\"Preprocessing\", \"pred_stat_list\").split(\",\")\n",
    "        ]\n",
    "    )\n",
    "    + flatten(\n",
    "        [\n",
    "            [\n",
    "                f\"opp_DEF_recent_{stat}\",\n",
    "                f\"opp_GK_recent_{stat}\",\n",
    "                f\"opp_MID_recent_{stat}\",\n",
    "                f\"opp_FWD_recent_{stat}\",\n",
    "            ]\n",
    "            for stat in configParser.get(\"Preprocessing\", \"pred_stat_list\").split(\",\")\n",
    "        ]\n",
    "    )\n",
    "    + flatten(\n",
    "        [\n",
    "            [\n",
    "                f\"team_DEF_recent_{stat}\",\n",
    "                f\"team_GK_recent_{stat}\",\n",
    "                f\"team_MID_recent_{stat}\",\n",
    "                f\"team_FWD_recent_{stat}\",\n",
    "            ]\n",
    "            for stat in configParser.get(\"Preprocessing\", \"pred_stat_list\").split(\",\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def basic_lasso(df, position):\n",
    "    position_df = df[df[\"position\"] == position]\n",
    "\n",
    "    position_df = normalize_columns(position_df, all_preds)\n",
    "    predictor_string = \" + \".join(all_preds)\n",
    "    model = sm.ols(\n",
    "        formula=f\"total_points ~ {predictor_string}\", data=position_df\n",
    "    ).fit_regularized(alpha=[0] + [0.4] * len(all_preds), L1_wt=1)\n",
    "    for param, value in zip(model.params.index, model.params):\n",
    "        if abs(value) > 0.0001:\n",
    "            print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for position in [\"GK\", \"DEF\", \"MID\", \"FWD\"]:\n",
    "    basic_lasso(preprocessed_df, position)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
